{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c426af48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🎉 VERIFIKASI DATASET BERHASIL TER-DOWNLOAD\n",
    "import glob\n",
    "\n",
    "print(\"🔍 VERIFIKASI DATASET URBANSOUND8K\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check audio folder structure\n",
    "if os.path.exists('audio'):\n",
    "    print(\"✅ Folder audio ditemukan!\")\n",
    "    \n",
    "    total_files = 0\n",
    "    for fold in range(1, 11):\n",
    "        fold_path = f'audio/fold{fold}'\n",
    "        if os.path.exists(fold_path):\n",
    "            wav_files = len(glob.glob(os.path.join(fold_path, \"*.wav\")))\n",
    "            total_files += wav_files\n",
    "            print(f\"   fold{fold}: {wav_files:4d} files\")\n",
    "        else:\n",
    "            print(f\"   fold{fold}: MISSING\")\n",
    "    \n",
    "    print(f\"\\n📊 TOTAL: {total_files}/8732 file audio\")\n",
    "    \n",
    "    if total_files == 8732:\n",
    "        print(\"🎉 DATASET LENGKAP!\")\n",
    "        print(\"✅ Siap untuk ekstraksi MFCC dari audio asli\")\n",
    "        DATASET_READY = True\n",
    "    elif total_files > 8000:\n",
    "        print(\"✅ Dataset hampir lengkap (>8000 files)\")\n",
    "        print(\"✅ Cukup untuk penelitian\")\n",
    "        DATASET_READY = True\n",
    "    else:\n",
    "        print(\"⚠️  Dataset tidak lengkap\")\n",
    "        DATASET_READY = False\n",
    "else:\n",
    "    print(\"❌ Folder audio tidak ditemukan\")\n",
    "    DATASET_READY = False\n",
    "\n",
    "# Test sample audio file\n",
    "if DATASET_READY:\n",
    "    sample_file = glob.glob(\"audio/fold1/*.wav\")[0]\n",
    "    print(f\"\\n🎵 Testing sample audio: {os.path.basename(sample_file)}\")\n",
    "    \n",
    "    try:\n",
    "        import librosa\n",
    "        audio, sr = librosa.load(sample_file, sr=16000)\n",
    "        print(f\"✅ Audio loaded: {len(audio)} samples, {sr}Hz\")\n",
    "        print(f\"   Duration: {len(audio)/sr:.2f} seconds\")\n",
    "        \n",
    "        # Quick MFCC test\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=20)\n",
    "        print(f\"✅ MFCC extraction: {mfccs.shape}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error testing audio: {e}\")\n",
    "\n",
    "print(f\"\\n🎯 STATUS: {'READY FOR REAL DATA' if DATASET_READY else 'USING SIMULATION'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb3e737",
   "metadata": {},
   "source": [
    "## 1. Import Libraries dan Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6157196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library yang diperlukan\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import librosa\n",
    "import librosa.display\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Deep Learning libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(\"Library berhasil diimport!\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68895cda",
   "metadata": {},
   "source": [
    "## 3. Ekstraksi Fitur MFCC\n",
    "### Sesuai Tabel 3: Parameter Ekstraksi Fitur MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269482a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter MFCC sesuai Tabel 3\n",
    "MFCC_PARAMS = {\n",
    "    'sampling_rate': 16000,  # 16kHz\n",
    "    'frame_size': 25,        # 25 ms (400 sample)\n",
    "    'hop_length': 10,        # 10 ms (160 sample)\n",
    "    'n_mfcc': 20,           # 20 koefisien MFCC\n",
    "    'window': 'hamming',     # Hamming window\n",
    "    'n_filter_mel': 26,      # 26 filter mel\n",
    "    'n_fft': 512            # 512 FFT\n",
    "}\n",
    "\n",
    "# Fungsi untuk ekstraksi MFCC\n",
    "def extract_mfcc_features(file_path, max_len=87):\n",
    "    \"\"\"\n",
    "    Ekstraksi fitur MFCC dari file audio\n",
    "    max_len: panjang maksimum sequence (sesuai matriks 20x4x1)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load audio file\n",
    "        audio, sr = librosa.load(file_path, sr=MFCC_PARAMS['sampling_rate'])\n",
    "        \n",
    "        # Ekstraksi MFCC\n",
    "        mfccs = librosa.feature.mfcc(\n",
    "            y=audio,\n",
    "            sr=sr,\n",
    "            n_mfcc=MFCC_PARAMS['n_mfcc'],\n",
    "            n_fft=MFCC_PARAMS['n_fft'],\n",
    "            hop_length=int(sr * MFCC_PARAMS['hop_length'] / 1000),\n",
    "            win_length=int(sr * MFCC_PARAMS['frame_size'] / 1000),\n",
    "            window=MFCC_PARAMS['window']\n",
    "        )\n",
    "        \n",
    "        # Normalisasi\n",
    "        mfccs = np.mean(mfccs.T, axis=0)\n",
    "        \n",
    "        # Padding atau truncate ke ukuran tetap\n",
    "        if len(mfccs) > max_len:\n",
    "            mfccs = mfccs[:max_len]\n",
    "        else:\n",
    "            mfccs = np.pad(mfccs, (0, max_len - len(mfccs)), mode='constant')\n",
    "            \n",
    "        return mfccs\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return np.zeros(max_len)\n",
    "\n",
    "print(\"Fungsi ekstraksi MFCC telah didefinisikan!\")\n",
    "print(f\"Parameter MFCC: {MFCC_PARAMS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8202fc8c",
   "metadata": {},
   "source": [
    "## 4. Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610205df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🎯 EKSTRAKSI FITUR MFCC DARI AUDIO ASLI\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"🎵 EKSTRAKSI FITUR MFCC DARI DATA AUDIO ASLI\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def extract_real_features_from_urbansound8k():\n",
    "    \"\"\"\n",
    "    Ekstraksi fitur MFCC dari dataset UrbanSound8K yang sesungguhnya\n",
    "    Menggunakan 8732 file audio WAV asli\n",
    "    \"\"\"\n",
    "    \n",
    "    if not DATASET_READY:\n",
    "        print(\"❌ Dataset tidak siap, menggunakan simulasi...\")\n",
    "        return simulate_mfcc_features(df), df['classID'].values, None\n",
    "    \n",
    "    features = []\n",
    "    labels = []\n",
    "    file_info = []\n",
    "    failed_files = []\n",
    "    \n",
    "    print(f\"📊 Total file yang akan diproses: {len(df)}\")\n",
    "    print(\"🔄 Memulai ekstraksi MFCC...\")\n",
    "    \n",
    "    # Loop through each audio file in metadata\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Ekstraksi MFCC\"):\n",
    "        # Construct full file path\n",
    "        fold_num = row['fold']\n",
    "        filename = row['slice_file_name']\n",
    "        audio_file_path = os.path.join('audio', f\"fold{fold_num}\", filename)\n",
    "        \n",
    "        try:\n",
    "            if not os.path.exists(audio_file_path):\n",
    "                failed_files.append(f\"{filename} (not found)\")\n",
    "                continue\n",
    "                \n",
    "            # Extract MFCC features\n",
    "            mfcc_features = extract_mfcc_features_enhanced(audio_file_path, target_length=87)\n",
    "            \n",
    "            if mfcc_features is not None:\n",
    "                features.append(mfcc_features)\n",
    "                labels.append(row['classID'])\n",
    "                file_info.append({\n",
    "                    'filename': filename,\n",
    "                    'fold': fold_num,\n",
    "                    'class': row['class'],\n",
    "                    'classID': row['classID']\n",
    "                })\n",
    "            else:\n",
    "                failed_files.append(f\"{filename} (extraction failed)\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            failed_files.append(f\"{filename} (error: {str(e)[:50]})\")\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    if features:\n",
    "        features = np.array(features)\n",
    "        labels = np.array(labels)\n",
    "        \n",
    "        print(f\"\\n✅ EKSTRAKSI BERHASIL!\")\n",
    "        print(f\"📊 File berhasil: {len(features)}/8732\")\n",
    "        print(f\"📊 File gagal: {len(failed_files)}\")\n",
    "        print(f\"📊 Shape fitur: {features.shape}\")\n",
    "        print(f\"📊 Shape label: {labels.shape}\")\n",
    "        print(f\"📊 Unique classes: {len(np.unique(labels))}\")\n",
    "        \n",
    "        if failed_files:\n",
    "            print(f\"\\n⚠️  Beberapa file gagal diproses:\")\n",
    "            for fail in failed_files[:5]:  # Show first 5\n",
    "                print(f\"   - {fail}\")\n",
    "            if len(failed_files) > 5:\n",
    "                print(f\"   ... dan {len(failed_files)-5} file lainnya\")\n",
    "        \n",
    "        # Calculate success rate\n",
    "        success_rate = len(features) / len(df) * 100\n",
    "        print(f\"\\n📈 Success Rate: {success_rate:.1f}%\")\n",
    "        \n",
    "        if success_rate > 95:\n",
    "            print(\"🎉 EXCELLENT! Ekstraksi hampir sempurna\")\n",
    "        elif success_rate > 90:\n",
    "            print(\"✅ GOOD! Ekstraksi berhasil dengan baik\")\n",
    "        else:\n",
    "            print(\"⚠️  MODERATE! Beberapa file bermasalah\")\n",
    "            \n",
    "        return features, labels, file_info\n",
    "    else:\n",
    "        print(\"❌ Tidak ada file yang berhasil diekstrak!\")\n",
    "        return None, None, None\n",
    "\n",
    "def extract_mfcc_features_enhanced(file_path, target_length=87):\n",
    "    \"\"\"\n",
    "    Ekstraksi fitur MFCC yang robust dari file audio\n",
    "    Optimized untuk publikasi SINTA\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load audio file\n",
    "        audio, sr = librosa.load(file_path, sr=MFCC_PARAMS['sampling_rate'])\n",
    "        \n",
    "        # Check minimum duration\n",
    "        if len(audio) < sr * 0.5:  # Minimum 0.5 detik\n",
    "            return None\n",
    "        \n",
    "        # Calculate parameters\n",
    "        hop_length_samples = int(sr * MFCC_PARAMS['hop_length'] / 1000)\n",
    "        win_length_samples = int(sr * MFCC_PARAMS['frame_size'] / 1000)\n",
    "        \n",
    "        # Extract MFCC features\n",
    "        mfccs = librosa.feature.mfcc(\n",
    "            y=audio,\n",
    "            sr=sr,\n",
    "            n_mfcc=MFCC_PARAMS['n_mfcc'],\n",
    "            n_fft=MFCC_PARAMS['n_fft'],\n",
    "            hop_length=hop_length_samples,\n",
    "            win_length=win_length_samples,\n",
    "            window=MFCC_PARAMS['window'],\n",
    "            n_mels=MFCC_PARAMS.get('n_filter_mel', 26)\n",
    "        )\n",
    "        \n",
    "        # Statistical aggregation untuk representasi yang stabil\n",
    "        mfcc_mean = np.mean(mfccs, axis=1)\n",
    "        mfcc_std = np.std(mfccs, axis=1)\n",
    "        mfcc_delta = librosa.feature.delta(mfccs)\n",
    "        mfcc_delta_mean = np.mean(mfcc_delta, axis=1)\n",
    "        \n",
    "        # Combine statistical features\n",
    "        combined_features = np.concatenate([mfcc_mean, mfcc_std, mfcc_delta_mean])\n",
    "        \n",
    "        # Normalize to target length\n",
    "        if len(combined_features) > target_length:\n",
    "            combined_features = combined_features[:target_length]\n",
    "        else:\n",
    "            combined_features = np.pad(combined_features, \n",
    "                                     (0, target_length - len(combined_features)), \n",
    "                                     mode='constant', constant_values=0)\n",
    "        \n",
    "        return combined_features\n",
    "        \n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "# Fallback simulation function (jika diperlukan)\n",
    "def simulate_mfcc_features(metadata_df, target_length=87):\n",
    "    \"\"\"\n",
    "    Simulasi fitur MFCC untuk testing (fallback)\n",
    "    \"\"\"\n",
    "    print(\"⚠️  Menggunakan simulasi data (hanya untuk testing)\")\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    n_samples = len(metadata_df)\n",
    "    \n",
    "    # Simulasi dengan karakteristik realistis\n",
    "    features = []\n",
    "    for i in range(n_samples):\n",
    "        # Simulasi MFCC dengan pola yang berbeda per kelas\n",
    "        class_id = metadata_df.iloc[i]['classID']\n",
    "        base_pattern = np.random.normal(0, 1, target_length)\n",
    "        \n",
    "        # Add class-specific patterns\n",
    "        class_offset = class_id * 0.5\n",
    "        base_pattern += class_offset\n",
    "        \n",
    "        features.append(base_pattern)\n",
    "    \n",
    "    return np.array(features)\n",
    "\n",
    "# JALANKAN EKSTRAKSI\n",
    "print(\"🚀 MEMULAI EKSTRAKSI FITUR...\")\n",
    "\n",
    "# Extract features dari audio asli\n",
    "X, y, audio_file_info = extract_real_features_from_urbansound8k()\n",
    "\n",
    "if X is not None and y is not None:\n",
    "    print(f\"\\n📊 HASIL AKHIR EKSTRAKSI:\")\n",
    "    print(f\"✅ Features shape: {X.shape}\")\n",
    "    print(f\"✅ Labels shape: {y.shape}\")\n",
    "    print(f\"✅ Classes: {len(np.unique(y))} unique classes\")\n",
    "    print(f\"✅ Mode: {'REAL AUDIO DATA' if audio_file_info else 'SIMULATION'}\")\n",
    "    \n",
    "    # Tampilkan distribusi kelas\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    print(f\"\\n📈 Distribusi per kelas:\")\n",
    "    for class_id, count in zip(unique, counts):\n",
    "        class_name = df[df['classID'] == class_id]['class'].iloc[0]\n",
    "        print(f\"   {class_id}: {class_name:20s} - {count:4d} samples\")\n",
    "        \n",
    "else:\n",
    "    print(\"❌ Ekstraksi gagal total!\")\n",
    "    \n",
    "print(f\"\\n🎯 STATUS: {'READY FOR TRAINING' if X is not None else 'FAILED'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a63887b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔧 PREPROCESSING DATA UNTUK CNN\n",
    "print(\"🔧 PREPROCESSING DATA UNTUK CNN\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"📊 Input features shape: {X.shape}\")\n",
    "print(f\"📊 Input labels shape: {y.shape}\")\n",
    "\n",
    "# Analyze feature dimensions\n",
    "n_samples, n_features = X.shape\n",
    "print(f\"📊 Samples: {n_samples}, Features: {n_features}\")\n",
    "\n",
    "# Reshape untuk CNN input\n",
    "# Karena kita punya 87 features (20 MFCC + 20 STD + 20 Delta + padding)\n",
    "# Kita akan reshape ke format yang cocok untuk CNN\n",
    "\n",
    "if n_features == 87:\n",
    "    # Reshape ke (samples, height, width, channels) yang cocok untuk CNN\n",
    "    # Option 1: Treat as 1D signal\n",
    "    X_reshaped = X.reshape(X.shape[0], n_features, 1, 1)\n",
    "    input_shape = (n_features, 1, 1)\n",
    "    print(f\"✅ Reshaped to: {X_reshaped.shape} (1D signal format)\")\n",
    "    \n",
    "elif n_features == 60:  # Jika hanya 20*3 (MFCC + STD + Delta)\n",
    "    # Reshape ke 2D format\n",
    "    X_reshaped = X.reshape(X.shape[0], 20, 3, 1)\n",
    "    input_shape = (20, 3, 1)\n",
    "    print(f\"✅ Reshaped to: {X_reshaped.shape} (2D MFCC format)\")\n",
    "    \n",
    "else:\n",
    "    # Generic reshape untuk feature length apapun\n",
    "    # Cari faktor yang paling mendekati square\n",
    "    import math\n",
    "    sqrt_feat = int(math.sqrt(n_features))\n",
    "    \n",
    "    if sqrt_feat * sqrt_feat == n_features:\n",
    "        # Perfect square\n",
    "        X_reshaped = X.reshape(X.shape[0], sqrt_feat, sqrt_feat, 1)\n",
    "        input_shape = (sqrt_feat, sqrt_feat, 1)\n",
    "        print(f\"✅ Reshaped to: {X_reshaped.shape} (square format)\")\n",
    "    else:\n",
    "        # Find best rectangular shape\n",
    "        for h in range(1, n_features + 1):\n",
    "            if n_features % h == 0:\n",
    "                w = n_features // h\n",
    "                if h <= w and w <= h * 2:  # Prefer rectangular shape\n",
    "                    X_reshaped = X.reshape(X.shape[0], h, w, 1)\n",
    "                    input_shape = (h, w, 1)\n",
    "                    print(f\"✅ Reshaped to: {X_reshaped.shape} (rectangular format {h}x{w})\")\n",
    "                    break\n",
    "        else:\n",
    "            # Fallback: force into 1D\n",
    "            X_reshaped = X.reshape(X.shape[0], n_features, 1, 1)\n",
    "            input_shape = (n_features, 1, 1)\n",
    "            print(f\"✅ Reshaped to: {X_reshaped.shape} (fallback 1D format)\")\n",
    "\n",
    "# Encode labels\n",
    "num_classes = len(np.unique(y))\n",
    "y_categorical = to_categorical(y, num_classes=num_classes)\n",
    "\n",
    "print(f\"📊 Number of classes: {num_classes}\")\n",
    "print(f\"📊 Labels encoded to: {y_categorical.shape}\")\n",
    "\n",
    "# Split data dengan stratified sampling\n",
    "print(f\"\\n🔄 Splitting data...\")\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X_reshaped, y_categorical, \n",
    "    test_size=0.3, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, \n",
    "    test_size=0.5, \n",
    "    random_state=42, \n",
    "    stratify=y_temp.argmax(axis=1)\n",
    ")\n",
    "\n",
    "print(f\"✅ Training set: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"✅ Validation set: {X_val.shape}, {y_val.shape}\")\n",
    "print(f\"✅ Test set: {X_test.shape}, {y_test.shape}\")\n",
    "\n",
    "# Verify class distribution\n",
    "print(f\"\\n📈 Class distribution in splits:\")\n",
    "for split_name, y_split in [(\"Train\", y_train), (\"Val\", y_val), (\"Test\", y_test)]:\n",
    "    class_counts = np.sum(y_split, axis=0)\n",
    "    print(f\"   {split_name:5s}: {class_counts.astype(int)}\")\n",
    "\n",
    "print(f\"\\n🎯 Input shape for CNN: {input_shape}\")\n",
    "print(f\"🎯 Ready for model training with REAL AUDIO DATA!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bdcc49",
   "metadata": {},
   "source": [
    "## 5. Arsitektur Model CNN\n",
    "### Sesuai Tabel 4: Arsitektur CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b817b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    Membangun arsitektur CNN yang dioptimalkan untuk fitur MFCC\n",
    "    Input: (87, 1, 1) - 87 fitur MFCC dari audio asli\n",
    "    \"\"\"\n",
    "    print(f\"🏗️  Building CNN for input shape: {input_shape}\")\n",
    "    \n",
    "    model = Sequential([\n",
    "        # Input Layer - Fitur MFCC (87, 1, 1)\n",
    "        tf.keras.layers.Input(shape=input_shape),\n",
    "        \n",
    "        # Conv2D_1: 32 filter, kernel disesuaikan dengan input 1D\n",
    "        Conv2D(32, (3, 1), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        \n",
    "        # Conv2D_2: 64 filter untuk ekstraksi fitur yang lebih dalam\n",
    "        Conv2D(64, (3, 1), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 1)),\n",
    "        \n",
    "        # Conv2D_3: 128 filter untuk pattern recognition\n",
    "        Conv2D(128, (3, 1), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # Global Average Pooling untuk mengurangi overfitting\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        \n",
    "        # Dense layers\n",
    "        Dense(256, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        \n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        # Output layer\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Buat model dengan input shape yang benar\n",
    "model = create_cnn_model(input_shape, num_classes)\n",
    "\n",
    "# Tampilkan arsitektur model\n",
    "print(\"\\n📋 ARSITEKTUR MODEL CNN:\")\n",
    "print(\"=\" * 50)\n",
    "model.summary()\n",
    "\n",
    "# Hitung parameter\n",
    "total_params = model.count_params()\n",
    "trainable_params = sum([np.prod(var.shape) for var in model.trainable_variables])\n",
    "print(f\"\\n📊 MODEL STATISTICS:\")\n",
    "print(f\"   Total parameters: {total_params:,}\")\n",
    "print(f\"   Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"   Model size (approx): {total_params * 4 / (1024*1024):.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf77cae8",
   "metadata": {},
   "source": [
    "## 6. Kompilasi dan Training Model\n",
    "### Sesuai Tabel 5: Parameter Pelatihan Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ef299e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter pelatihan sesuai Tabel 5\n",
    "TRAINING_PARAMS = {\n",
    "    'optimizer': 'Adam',\n",
    "    'learning_rate': 1e-4,\n",
    "    'loss_function': 'categorical_crossentropy',\n",
    "    'batch_size': 32,\n",
    "    'epochs': 50,\n",
    "    'early_stopping': True\n",
    "}\n",
    "\n",
    "# Kompilasi model\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=TRAINING_PARAMS['learning_rate']),\n",
    "    loss=TRAINING_PARAMS['loss_function'],\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=10,\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        'best_urban_sound_model.h5',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"Model berhasil dikompilasi!\")\n",
    "print(f\"Parameter training: {TRAINING_PARAMS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3573fed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training model\n",
    "print(\"Memulai training model...\")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=TRAINING_PARAMS['batch_size'],\n",
    "    epochs=TRAINING_PARAMS['epochs'],\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Training selesai!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8c4311",
   "metadata": {},
   "source": [
    "## 7. Evaluasi Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c41830a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d971873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluasi pada test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "# Prediksi\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Classification report\n",
    "class_names = df['class'].unique()\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true_classes, y_pred_classes, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0668dc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9df7328",
   "metadata": {},
   "source": [
    "## 8. Implementasi Sistem Multimodal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a446c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodalFeedbackSystem:\n",
    "    \"\"\"\n",
    "    Sistem umpan balik multimodal untuk penyandang tunarungu\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.class_names = [\n",
    "            'air_conditioner', 'car_horn', 'children_playing', 'dog_bark',\n",
    "            'drilling', 'engine_idling', 'gun_shot', 'jackhammer',\n",
    "            'siren', 'street_music'\n",
    "        ]\n",
    "        \n",
    "        # Pemetaan untuk umpan balik visual\n",
    "        self.visual_mapping = {\n",
    "            'air_conditioner': {'color': 'blue', 'icon': '❄️', 'priority': 'low'},\n",
    "            'car_horn': {'color': 'red', 'icon': '🚗', 'priority': 'high'},\n",
    "            'children_playing': {'color': 'yellow', 'icon': '👶', 'priority': 'medium'},\n",
    "            'dog_bark': {'color': 'brown', 'icon': '🐕', 'priority': 'medium'},\n",
    "            'drilling': {'color': 'orange', 'icon': '🔨', 'priority': 'high'},\n",
    "            'engine_idling': {'color': 'gray', 'icon': '🚙', 'priority': 'medium'},\n",
    "            'gun_shot': {'color': 'red', 'icon': '⚠️', 'priority': 'critical'},\n",
    "            'jackhammer': {'color': 'orange', 'icon': '🔧', 'priority': 'high'},\n",
    "            'siren': {'color': 'red', 'icon': '🚨', 'priority': 'critical'},\n",
    "            'street_music': {'color': 'purple', 'icon': '🎵', 'priority': 'low'}\n",
    "        }\n",
    "        \n",
    "        # Pemetaan untuk umpan balik haptik\n",
    "        self.haptic_mapping = {\n",
    "            'air_conditioner': {'pattern': 'continuous_low', 'intensity': 30},\n",
    "            'car_horn': {'pattern': 'sharp_burst', 'intensity': 90},\n",
    "            'children_playing': {'pattern': 'gentle_wave', 'intensity': 50},\n",
    "            'dog_bark': {'pattern': 'short_pulse', 'intensity': 70},\n",
    "            'drilling': {'pattern': 'aggressive_vibration', 'intensity': 85},\n",
    "            'engine_idling': {'pattern': 'steady_rumble', 'intensity': 40},\n",
    "            'gun_shot': {'pattern': 'shock_burst', 'intensity': 100},\n",
    "            'jackhammer': {'pattern': 'rapid_pulse', 'intensity': 95},\n",
    "            'siren': {'pattern': 'alternating_high', 'intensity': 100},\n",
    "            'street_music': {'pattern': 'rhythmic_pulse', 'intensity': 35}\n",
    "        }\n",
    "    \n",
    "    def predict_sound(self, audio_features):\n",
    "        \"\"\"\n",
    "        Prediksi kelas suara dari fitur audio\n",
    "        \"\"\"\n",
    "        # Reshape untuk prediksi\n",
    "        features_reshaped = audio_features.reshape(1, 20, 1, 1)\n",
    "        \n",
    "        # Prediksi\n",
    "        prediction = self.model.predict(features_reshaped, verbose=0)\n",
    "        predicted_class_idx = np.argmax(prediction[0])\n",
    "        confidence = prediction[0][predicted_class_idx]\n",
    "        \n",
    "        predicted_class = self.class_names[predicted_class_idx]\n",
    "        \n",
    "        return predicted_class, confidence\n",
    "    \n",
    "    def generate_visual_feedback(self, sound_class, confidence):\n",
    "        \"\"\"\n",
    "        Generate umpan balik visual\n",
    "        \"\"\"\n",
    "        visual_info = self.visual_mapping[sound_class]\n",
    "        \n",
    "        feedback = {\n",
    "            'sound_detected': sound_class,\n",
    "            'confidence': f\"{confidence:.2f}\",\n",
    "            'visual_cue': {\n",
    "                'color': visual_info['color'],\n",
    "                'icon': visual_info['icon'],\n",
    "                'priority': visual_info['priority'],\n",
    "                'alert_level': self._get_alert_level(visual_info['priority'])\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return feedback\n",
    "    \n",
    "    def generate_haptic_feedback(self, sound_class, confidence):\n",
    "        \"\"\"\n",
    "        Generate umpan balik haptik\n",
    "        \"\"\"\n",
    "        haptic_info = self.haptic_mapping[sound_class]\n",
    "        \n",
    "        # Adjust intensity based on confidence\n",
    "        adjusted_intensity = int(haptic_info['intensity'] * confidence)\n",
    "        \n",
    "        feedback = {\n",
    "            'pattern': haptic_info['pattern'],\n",
    "            'intensity': adjusted_intensity,\n",
    "            'duration': self._calculate_duration(sound_class),\n",
    "            'frequency': self._calculate_frequency(sound_class)\n",
    "        }\n",
    "        \n",
    "        return feedback\n",
    "    \n",
    "    def _get_alert_level(self, priority):\n",
    "        alert_levels = {\n",
    "            'low': 1,\n",
    "            'medium': 2,\n",
    "            'high': 3,\n",
    "            'critical': 4\n",
    "        }\n",
    "        return alert_levels.get(priority, 1)\n",
    "    \n",
    "    def _calculate_duration(self, sound_class):\n",
    "        # Duration in milliseconds\n",
    "        durations = {\n",
    "            'gun_shot': 100,\n",
    "            'siren': 1000,\n",
    "            'car_horn': 500,\n",
    "            'jackhammer': 800,\n",
    "            'drilling': 600,\n",
    "            'dog_bark': 300,\n",
    "            'children_playing': 400,\n",
    "            'engine_idling': 1500,\n",
    "            'air_conditioner': 2000,\n",
    "            'street_music': 1200\n",
    "        }\n",
    "        return durations.get(sound_class, 500)\n",
    "    \n",
    "    def _calculate_frequency(self, sound_class):\n",
    "        # Frequency in Hz for haptic feedback\n",
    "        frequencies = {\n",
    "            'gun_shot': 200,\n",
    "            'siren': 150,\n",
    "            'car_horn': 180,\n",
    "            'jackhammer': 250,\n",
    "            'drilling': 220,\n",
    "            'dog_bark': 120,\n",
    "            'children_playing': 80,\n",
    "            'engine_idling': 60,\n",
    "            'air_conditioner': 40,\n",
    "            'street_music': 100\n",
    "        }\n",
    "        return frequencies.get(sound_class, 100)\n",
    "    \n",
    "    def process_real_time(self, audio_features):\n",
    "        \"\"\"\n",
    "        Pemrosesan real-time untuk sistem multimodal\n",
    "        \"\"\"\n",
    "        # Prediksi suara\n",
    "        sound_class, confidence = self.predict_sound(audio_features)\n",
    "        \n",
    "        # Generate feedback\n",
    "        visual_feedback = self.generate_visual_feedback(sound_class, confidence)\n",
    "        haptic_feedback = self.generate_haptic_feedback(sound_class, confidence)\n",
    "        \n",
    "        return {\n",
    "            'timestamp': pd.Timestamp.now(),\n",
    "            'prediction': {\n",
    "                'class': sound_class,\n",
    "                'confidence': confidence\n",
    "            },\n",
    "            'visual_feedback': visual_feedback,\n",
    "            'haptic_feedback': haptic_feedback\n",
    "        }\n",
    "\n",
    "# Inisialisasi sistem multimodal\n",
    "multimodal_system = MultimodalFeedbackSystem(model)\n",
    "print(\"Sistem multimodal telah diinisialisasi!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ac2174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo sistem multimodal\n",
    "sample_idx = 0\n",
    "audio_sample = X_test[sample_idx]\n",
    "true_label_idx = np.argmax(y_test[sample_idx])\n",
    "\n",
    "class_names_list = ['air_conditioner', 'car_horn', 'children_playing', 'dog_bark',\n",
    "                   'drilling', 'engine_idling', 'gun_shot', 'jackhammer',\n",
    "                   'siren', 'street_music']\n",
    "\n",
    "print(f\"True class: {class_names_list[true_label_idx]}\")\n",
    "\n",
    "result = multimodal_system.process_real_time(audio_sample)\n",
    "\n",
    "print(f\"Predicted: {result['prediction']['class']}\")\n",
    "print(f\"Confidence: {result['prediction']['confidence']:.3f}\")\n",
    "print(f\"Visual: {result['visual_feedback']['visual_cue']['icon']} {result['visual_feedback']['visual_cue']['color']}\")\n",
    "print(f\"Haptic: {result['haptic_feedback']['pattern']}, {result['haptic_feedback']['intensity']}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af2e1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisis performa per kelas\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Hitung metrik untuk setiap kelas\n",
    "precision, recall, f1, support = precision_recall_fscore_support(\n",
    "    y_true_classes, y_pred_classes, average=None\n",
    ")\n",
    "\n",
    "# Buat DataFrame hasil\n",
    "results_df = pd.DataFrame({\n",
    "    'Class': class_names,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1-Score': f1,\n",
    "    'Support': support\n",
    "})\n",
    "\n",
    "results_df = results_df.round(4)\n",
    "print(\"Hasil Evaluasi per Kelas:\")\n",
    "print(results_df)\n",
    "\n",
    "# Metrik overall\n",
    "overall_precision = np.mean(precision)\n",
    "overall_recall = np.mean(recall)\n",
    "overall_f1 = np.mean(f1)\n",
    "\n",
    "print(f\"\\nMetrik Overall:\")\n",
    "print(f\"Akurasi: {test_accuracy:.4f}\")\n",
    "print(f\"Precision (macro): {overall_precision:.4f}\")\n",
    "print(f\"Recall (macro): {overall_recall:.4f}\")\n",
    "print(f\"F1-Score (macro): {overall_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da51fbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisasi performa per kelas\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot 1: Precision, Recall, F1-Score per kelas\n",
    "plt.subplot(1, 3, 1)\n",
    "x = np.arange(len(class_names))\n",
    "width = 0.25\n",
    "\n",
    "plt.bar(x - width, precision, width, label='Precision', alpha=0.8)\n",
    "plt.bar(x, recall, width, label='Recall', alpha=0.8)\n",
    "plt.bar(x + width, f1, width, label='F1-Score', alpha=0.8)\n",
    "\n",
    "plt.xlabel('Kelas Suara')\n",
    "plt.ylabel('Skor')\n",
    "plt.title('Metrik Evaluasi per Kelas')\n",
    "plt.xticks(x, class_names, rotation=45, ha='right')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Distribusi confidence score\n",
    "plt.subplot(1, 3, 2)\n",
    "confidence_scores = np.max(y_pred, axis=1)\n",
    "plt.hist(confidence_scores, bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "plt.xlabel('Confidence Score')\n",
    "plt.ylabel('Frekuensi')\n",
    "plt.title('Distribusi Confidence Score')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Accuracy vs Confidence threshold\n",
    "plt.subplot(1, 3, 3)\n",
    "thresholds = np.arange(0.1, 1.0, 0.05)\n",
    "accuracies = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    mask = confidence_scores >= threshold\n",
    "    if np.sum(mask) > 0:\n",
    "        acc = accuracy_score(y_true_classes[mask], y_pred_classes[mask])\n",
    "        accuracies.append(acc)\n",
    "    else:\n",
    "        accuracies.append(0)\n",
    "\n",
    "plt.plot(thresholds, accuracies, marker='o', linewidth=2)\n",
    "plt.xlabel('Confidence Threshold')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs Confidence Threshold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf85e1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simpan model dan hasil\n",
    "model.save('urban_sound_multimodal_model.h5')\n",
    "results_df.to_csv('evaluation_results.csv', index=False)\n",
    "\n",
    "# Simpan parameter penelitian\n",
    "research_params = {\n",
    "    'mfcc_params': MFCC_PARAMS,\n",
    "    'training_params': TRAINING_PARAMS,\n",
    "    'model_performance': {\n",
    "        'test_accuracy': float(test_accuracy),\n",
    "        'test_loss': float(test_loss),\n",
    "        'precision_macro': float(overall_precision),\n",
    "        'recall_macro': float(overall_recall),\n",
    "        'f1_score_macro': float(overall_f1)\n",
    "    }\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('research_parameters.json', 'w') as f:\n",
    "    json.dump(research_params, f, indent=2)\n",
    "\n",
    "print(\"Model dan hasil penelitian telah disimpan!\")\n",
    "print(\"Files:\")\n",
    "print(\"- urban_sound_multimodal_model.h5\")\n",
    "print(\"- evaluation_results.csv\")\n",
    "print(\"- research_parameters.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
